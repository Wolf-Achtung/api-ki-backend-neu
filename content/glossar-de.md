# Glossar (DE) – kompakt

**AI Act (EU)** – Europäische Verordnung zu KI‑Systemen mit Pflichten je nach Risikoklasse (Transparenz, Datenqualität, Aufsicht, Dokumentation).  
**Alignment** – Ausrichtung eines Modells auf gewünschte Ziele/Verhalten (Sicherheit, Ethik, Stil).  
**API** – Programmierschnittstelle zur Anbindung oder Automatisierung von Software.  
**Assistive AI** – KI als Unterstützung in Workflows (nicht vollautonom).  
**Benchmark** – Vergleichsmaßstab zur Einordnung der eigenen Performance.  
**Chatbot** – Dialogsystem auf Basis eines LLMs, z. B. für Support oder interne Auskünfte.  
**Context Window** – Menge an Tokens, die ein Modell pro Anfrage verarbeiten kann.  
**Copilot** – Assistent, der in bestehende Tools integriert (z. B. M365 Copilot).  
**Data Leakage** – Unbeabsichtigte Preisgabe sensibler Daten durch Logs, Trainingsdaten oder Prompting.  
**Data Loss Prevention (DLP)** – Techniken/Regeln, die Datenabflüsse verhindern.  
**Dataset Governance** – Richtlinien für Herkunft, Qualität und Nutzung von Trainings-/Kontextdaten.  
**Embeddings** – Vektordarstellung von Text/Bildern für Suche, RAG u. ä.  
**Enterprise Readiness** – Erfüllung von Anforderungen an Sicherheit, Compliance, Betrieb & Support.  
**Few‑shot Prompting** – Beispiele im Prompt, um das Modell zu steuern.  
**Fine‑Tuning** – Nachtrainieren eines Modells auf eigene Daten.  
**Guardrails** – Prüfschritte (Policies, Tools), die Ausgaben validieren/filtern.  
**Halluzination** – Plausibel klingende, aber faktisch falsche Ausgabe eines Modells.  
**Inference** – Ausführung eines Modells zur Beantwortung einer Anfrage.  
**KB / Wissensbasis** – Kuratierte, versionierte Sammlung relevanter Dokumente.  
**Latency** – Antwortzeit eines Systems.  
**LLM** – Large Language Model (z. B. GPT‑4.1, Claude 3.5, Llama 3.1).  
**Maturity Index** – Indikator für den KI‑Reifegrad eines Unternehmens.  
**Open‑Source Modelle** – Frei verfügbare Modelle (z. B. Llama, Mistral) – oft lokal einsetzbar.  
**Prompt** – Eingabeinstruktion an ein LLM.  
**Prompt Leakage** – Preisgabe sensibler Systeminstruktionen (z. B. durch Rückfragen).  
**RAG** – Retrieval‑Augmented Generation: Modell nutzt eigene Wissensbasis.  
**Red Teaming** – Systematische Tests gegen Missbrauch/Fehler (Sicherheit).  
**Responsible AI** – Verantwortungsvolle Entwicklung/Nutzung mit Ethik & Compliance.  
**Runtime Cost** – Laufzeit‑/Token‑Kosten pro Anfrage.  
**Service Levels (SLA)** – Vereinbarte Verfügbarkeits‑/Performance‑Grenzen.  
**Shadow‑IT** – Nicht genehmigte Tools/Automationen, die Risiken bergen.  
**SLA Drift** – Schleichende Verschlechterung gegenüber vereinbarten Werten.  
**Tavily / Perplexity** – Recherche‑APIs, die Web‑Quellen strukturiert aufbereiten.  
**Token** – Grundeinheit der Modellverarbeitung (~3‑4 Zeichen).  
**Toolformer** – Modell nutzt externe Tools/Plugins zur Problemlösung.  
**Vector Store** – Datenbank für Embeddings (z. B. FAISS, pgvector).

*Quelle: kuratiert, Stand {{LAST_UPDATED}}.*
